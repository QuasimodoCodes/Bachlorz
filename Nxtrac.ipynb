{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "def extract_from_pdf(file_path):\n",
    "    try:\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            text = \"\\n\".join([page.extract_text() for page in pdf.pages])\n",
    "            if text.strip():\n",
    "                # Clean up the text (remove extra line breaks, unwanted spaces)\n",
    "                cleaned_text = re.sub(r'\\s+', ' ', text.strip())\n",
    "                return cleaned_text\n",
    "            else:\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from PDF {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_from_excel(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=None)\n",
    "        all_text = \"\"\n",
    "        for sheet_name, sheet_df in df.items():\n",
    "            # Flatten any merged cells by forward filling values\n",
    "            sheet_df = sheet_df.ffill()  # Replace fillna with ffill directly\n",
    "            sheet_text = sheet_df.to_string(index=False)  # Remove indices for cleaner output\n",
    "            if sheet_text.strip():\n",
    "                all_text += sheet_text + \"\\n\"\n",
    "        if all_text.strip():\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', all_text.strip())  # Clean up unwanted spaces\n",
    "            return cleaned_text\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from Excel {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_data_from_folders(folder_paths):\n",
    "    data = []\n",
    "    files_to_process = []\n",
    "\n",
    "    # Collect files from all specified folders\n",
    "    for folder_path in folder_paths:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file_name in files:\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                if file_path.lower().endswith((\".pdf\", \".xlsx\", \".xls\")):  # Case-insensitive handling\n",
    "                    files_to_process.append(file_path)\n",
    "\n",
    "    # Using tqdm to show a progress bar while processing files\n",
    "    for file_path in tqdm(files_to_process, desc=\"Processing Files\", unit=\"file\"):\n",
    "        if file_path.lower().endswith(\".pdf\"):\n",
    "            text = extract_from_pdf(file_path)\n",
    "            if text:\n",
    "                data.append({\"filename\": file_path, \"source_format\": \"pdf\", \"content\": text})\n",
    "        elif file_path.lower().endswith((\".xlsx\", \".xls\")):\n",
    "            text = extract_from_excel(file_path)\n",
    "            if text:\n",
    "                data.append({\"filename\": file_path, \"source_format\": \"xlsx\", \"content\": text})\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# folders:\n",
    "folder_paths = [\n",
    "    r\"C:\\Users\\spide\\OneDrive\\Desktop\\Bachlorz\\2022 - data\", \n",
    "    r\"C:\\Users\\spide\\OneDrive\\Desktop\\Bachlorz\\Tenders\"\n",
    "]\n",
    "df_data = extract_data_from_folders(folder_paths)\n",
    "\n",
    "if not df_data.empty:\n",
    "    print(f\"Extracted data from {len(df_data)} files.\")\n",
    "    print(df_data.head())\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    output_file = \"extracted_data.csv\"\n",
    "    df_data.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "else:\n",
    "    print(\"No data extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_from_pdf(file_path):\n",
    "    try:\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            text = \"\\n\".join([page.extract_text() for page in pdf.pages])\n",
    "            if text.strip():\n",
    "                # Clean up the text (remove extra line breaks, unwanted spaces)\n",
    "                cleaned_text = re.sub(r'\\s+', ' ', text.strip())\n",
    "                return cleaned_text\n",
    "            else:\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from PDF {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract text from Excel\n",
    "def extract_from_excel(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=None)\n",
    "        all_text = \"\"\n",
    "        for sheet_name, sheet_df in df.items():\n",
    "            # Flatten any merged cells by forward filling values\n",
    "            sheet_df = sheet_df.ffill()  # Replace fillna with ffill directly\n",
    "            sheet_text = sheet_df.to_string(index=False)  # Remove indices for cleaner output\n",
    "            if sheet_text.strip():\n",
    "                all_text += sheet_text + \"\\n\"\n",
    "        if all_text.strip():\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', all_text.strip())  # Clean up unwanted spaces\n",
    "            return cleaned_text\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from Excel {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract data from multiple folders\n",
    "def extract_data_from_folders(folder_paths):\n",
    "    data = []\n",
    "    files_to_process = []\n",
    "\n",
    "    # Iterate over each folder path\n",
    "    for folder_path in folder_paths:\n",
    "        print(f\"Checking folder: {folder_path}\")  # Debugging line\n",
    "        if os.path.exists(folder_path):  # Check if the folder exists\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                print(f\"Scanning folder: {root}\")  # Debugging line\n",
    "                for file_name in files:\n",
    "                    file_path = os.path.join(root, file_name)\n",
    "                    print(f\"Found file: {file_path}\")  # Debugging line\n",
    "                    \n",
    "                    # Check for supported file types (PDF, Excel)\n",
    "                    if file_path.lower().endswith((\".pdf\", \".xlsx\", \".xls\")):  # Case-insensitive handling\n",
    "                        files_to_process.append(file_path)\n",
    "        else:\n",
    "            print(f\"Folder not found: {folder_path}\")  # If folder is missing\n",
    "\n",
    "    # Start processing files with tqdm progress bar\n",
    "    print(f\"Total files to process: {len(files_to_process)}\")\n",
    "    \n",
    "    # Use tqdm to display the progress bar during processing\n",
    "    for file_path in tqdm(files_to_process, desc=\"Processing Files\", unit=\"file\"):\n",
    "        if file_path.lower().endswith(\".pdf\"):\n",
    "            text = extract_from_pdf(file_path)\n",
    "            if text:\n",
    "                data.append({\"filename\": file_path, \"source_format\": \"pdf\", \"content\": text})\n",
    "        elif file_path.lower().endswith((\".xlsx\", \".xls\")):\n",
    "            text = extract_from_excel(file_path)\n",
    "            if text:\n",
    "                data.append({\"filename\": file_path, \"source_format\": \"xlsx\", \"content\": text})\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Define the folder paths\n",
    "folder_paths = [\n",
    "    r\"C:\\Users\\spide\\OneDrive\\Desktop\\Bachlorz\\2022 - data\", \n",
    "    r\"C:\\Users\\spide\\OneDrive\\Desktop\\Bachlorz\\Tenders\"\n",
    "]\n",
    "\n",
    "# Extract data from both folders\n",
    "df_data = extract_data_from_folders(folder_paths)\n",
    "\n",
    "# If files were successfully extracted, print a summary and save to CSV\n",
    "if not df_data.empty:\n",
    "    print(f\"Extracted data from {len(df_data)} files.\")\n",
    "    print(df_data.head())\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    output_file = \"extracted_data.csv\"\n",
    "    df_data.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "else:\n",
    "    print(\"No data extracted.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
